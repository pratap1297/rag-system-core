#!/usr/bin/env python3
"""
Phase 4.1: FAISS Vector Storage Module Demonstration
Enterprise vector storage and similarity search with dual index management
"""

import asyncio
import numpy as np
import time
from datetime import datetime
from pathlib import Path

# Add src to path for imports
import sys
sys.path.insert(0, str(Path(__file__).parent / 'src'))

from storage.faiss_vector_storage import (
    FAISSVectorStorage, 
    VectorType, 
    IndexType, 
    SearchMode,
    VectorMetadata,
    create_vector_storage
)

async def main():
    """Demonstrate Phase 4.1 FAISS Vector Storage capabilities"""
    
    print("üöÄ Phase 4.1: FAISS Vector Storage Module Demo")
    print("=" * 60)
    
    # Configuration for demonstration
    config = {
        'storage_path': 'data/demo_vectors',
        
        # Chunk embedding index (1024-dim)
        'chunk_index_type': 'flat',  # Use flat for demo simplicity
        'chunk_dimension': 1024,
        'chunk_nlist': 50,
        'chunk_nprobe': 5,
        
        # Site embedding index (384-dim)
        'site_index_type': 'flat',
        'site_dimension': 384,
        'site_nlist': 25,
        'site_nprobe': 3,
        
        # Performance settings
        'max_workers': 2,
        
        # Cache configuration
        'cache': {
            'enabled': True,
            'max_size': 100,
            'ttl_hours': 1
        }
    }
    
    # Initialize vector storage
    print("\n1. üèóÔ∏è  Initializing FAISS Vector Storage...")
    storage = create_vector_storage(config)
    
    # Show initial statistics
    print("\n2. üìä Initial Storage Statistics:")
    chunk_stats = storage.get_index_stats(VectorType.CHUNK_EMBEDDING)
    site_stats = storage.get_index_stats(VectorType.SITE_EMBEDDING)
    
    print(f"   Chunk Index: {chunk_stats.total_vectors} vectors, {chunk_stats.memory_usage_mb:.2f} MB")
    print(f"   Site Index: {site_stats.total_vectors} vectors, {site_stats.memory_usage_mb:.2f} MB")
    
    # Generate sample vectors and metadata
    print("\n3. üéØ Generating Sample Vectors...")
    
    # Sample chunk embeddings (1024-dim)
    chunk_vectors = []
    chunk_metadata = []
    
    sample_documents = [
        ("Technical Manual - Safety Procedures", "technical_manual"),
        ("Incident Report - Equipment Failure", "incident_report"),
        ("Maintenance Log - Routine Inspection", "maintenance_log"),
        ("Safety Document - Emergency Protocols", "safety_document"),
        ("Procedural Guide - Operating Instructions", "procedural_document")
    ]
    
    for i, (doc_title, doc_type) in enumerate(sample_documents):
        # Generate random 1024-dim vector (normalized)
        vector = np.random.randn(1024).astype(np.float32)
        vector = vector / np.linalg.norm(vector)  # Normalize
        chunk_vectors.append(vector)
        
        # Create metadata
        metadata = VectorMetadata(
            vector_id=f"chunk_{i+1}",
            vector_type=VectorType.CHUNK_EMBEDDING,
            source_document=doc_title,
            chunk_index=i,
            document_type=doc_type,
            quality_score=0.8 + (i * 0.04),  # Varying quality scores
            embedding_provider="demo_provider",
            tags=[doc_type, "demo"],
            custom_metadata={
                "demo": True,
                "batch": "phase_4_1_demo"
            }
        )
        chunk_metadata.append(metadata)
    
    # Sample site embeddings (384-dim)
    site_vectors = []
    site_metadata = []
    
    sample_sites = [
        "Manufacturing Plant A",
        "Distribution Center B", 
        "Research Facility C"
    ]
    
    for i, site_name in enumerate(sample_sites):
        # Generate random 384-dim vector (normalized)
        vector = np.random.randn(384).astype(np.float32)
        vector = vector / np.linalg.norm(vector)  # Normalize
        site_vectors.append(vector)
        
        # Create metadata
        metadata = VectorMetadata(
            vector_id=f"site_{i+1}",
            vector_type=VectorType.SITE_EMBEDDING,
            source_document=f"{site_name} Overview",
            document_type="site_summary",
            quality_score=0.9,
            embedding_provider="demo_provider",
            tags=["site", "demo"],
            custom_metadata={
                "site_name": site_name,
                "demo": True
            }
        )
        site_metadata.append(metadata)
    
    print(f"   Generated {len(chunk_vectors)} chunk vectors (1024-dim)")
    print(f"   Generated {len(site_vectors)} site vectors (384-dim)")
    
    # Add vectors to storage
    print("\n4. üíæ Adding Vectors to Storage...")
    start_time = time.time()
    
    all_vectors = chunk_vectors + site_vectors
    all_metadata = chunk_metadata + site_metadata
    
    vector_ids = await storage.add_vectors(all_vectors, all_metadata)
    
    add_time = time.time() - start_time
    print(f"   ‚úÖ Added {len(vector_ids)} vectors in {add_time:.3f}s")
    print(f"   Vector IDs: {vector_ids}")
    
    # Show updated statistics
    print("\n5. üìà Updated Storage Statistics:")
    overall_stats = storage.get_storage_stats()
    
    print(f"   Total Vectors: {overall_stats['total_vectors']}")
    print(f"   Chunk Vectors: {overall_stats['chunk_vectors']}")
    print(f"   Site Vectors: {overall_stats['site_vectors']}")
    print(f"   Total Memory: {overall_stats['total_memory_mb']:.2f} MB")
    print(f"   Cache Enabled: {overall_stats['cache_enabled']}")
    
    # Demonstrate vector search
    print("\n6. üîç Demonstrating Vector Search...")
    
    # Create a query vector similar to the first chunk vector
    query_vector = chunk_vectors[0] + np.random.randn(1024) * 0.1  # Add small noise
    query_vector = query_vector / np.linalg.norm(query_vector)  # Normalize
    
    print("   Searching chunk embeddings...")
    search_start = time.time()
    
    chunk_results = await storage.search_vectors(
        query_vector=query_vector,
        vector_type=VectorType.CHUNK_EMBEDDING,
        k=3,
        search_mode=SearchMode.APPROXIMATE
    )
    
    search_time = time.time() - search_start
    print(f"   ‚úÖ Found {len(chunk_results)} results in {search_time:.3f}s")
    
    for i, result in enumerate(chunk_results, 1):
        print(f"   {i}. {result.vector_id}: {result.similarity_score:.4f} - {result.metadata['source_document']}")
    
    # Demonstrate different search modes
    print("\n7. ‚ö° Testing Different Search Modes...")
    
    modes = [SearchMode.EXACT, SearchMode.APPROXIMATE, SearchMode.HYBRID]
    
    for mode in modes:
        start_time = time.time()
        results = await storage.search_vectors(
            query_vector=query_vector,
            vector_type=VectorType.CHUNK_EMBEDDING,
            k=2,
            search_mode=mode
        )
        search_time = time.time() - start_time
        
        print(f"   {mode.value}: {len(results)} results in {search_time:.3f}s")
    
    # Demonstrate caching
    print("\n8. üöÄ Testing Search Caching...")
    
    # First search (cache miss)
    start_time = time.time()
    results1 = await storage.search_vectors(
        query_vector=query_vector,
        vector_type=VectorType.CHUNK_EMBEDDING,
        k=3
    )
    first_search_time = time.time() - start_time
    
    # Second search (cache hit)
    start_time = time.time()
    results2 = await storage.search_vectors(
        query_vector=query_vector,
        vector_type=VectorType.CHUNK_EMBEDDING,
        k=3
    )
    second_search_time = time.time() - start_time
    
    print(f"   First search (cache miss): {first_search_time:.3f}s")
    print(f"   Second search (cache hit): {second_search_time:.3f}s")
    print(f"   Speedup: {first_search_time/second_search_time:.1f}x")
    
    # Show cache statistics
    if storage.cache:
        cache_stats = storage.cache.get_stats()
        print(f"   Cache hit rate: {cache_stats['hit_rate']:.1f}%")
        print(f"   Cache size: {cache_stats['size']}/{cache_stats['max_size']}")
    
    # Demonstrate index statistics
    print("\n9. üìä Detailed Index Statistics:")
    
    chunk_stats = storage.get_index_stats(VectorType.CHUNK_EMBEDDING)
    site_stats = storage.get_index_stats(VectorType.SITE_EMBEDDING)
    
    print(f"   Chunk Index:")
    print(f"     - Vectors: {chunk_stats.total_vectors}")
    print(f"     - Memory: {chunk_stats.memory_usage_mb:.2f} MB")
    print(f"     - Searches: {chunk_stats.search_count}")
    print(f"     - Avg Search Time: {chunk_stats.avg_search_time:.3f}s")
    print(f"     - Trained: {chunk_stats.is_trained}")
    
    print(f"   Site Index:")
    print(f"     - Vectors: {site_stats.total_vectors}")
    print(f"     - Memory: {site_stats.memory_usage_mb:.2f} MB")
    print(f"     - Searches: {site_stats.search_count}")
    print(f"     - Avg Search Time: {site_stats.avg_search_time:.3f}s")
    print(f"     - Trained: {site_stats.is_trained}")
    
    # Demonstrate backup functionality
    print("\n10. üíæ Creating Index Backup...")
    backup_path = "data/demo_backup"
    
    await storage.backup_indices(backup_path)
    print(f"    ‚úÖ Backup created at: {backup_path}")
    
    # Performance summary
    print("\n11. üéØ Performance Summary:")
    total_operations = chunk_stats.search_count + site_stats.search_count
    total_vectors = overall_stats['total_vectors']
    
    print(f"    - Total vectors stored: {total_vectors}")
    print(f"    - Total search operations: {total_operations}")
    print(f"    - Average search time: {overall_stats['avg_search_time']:.3f}s")
    print(f"    - Memory efficiency: {total_vectors / max(overall_stats['total_memory_mb'], 0.1):.1f} vectors/MB")
    
    # Clean shutdown
    print("\n12. üîÑ Closing Storage...")
    await storage.close()
    
    print("\n‚úÖ Phase 4.1 Demo Completed Successfully!")
    print("=" * 60)
    print("Key Features Demonstrated:")
    print("  ‚úì Dual index management (chunk + site embeddings)")
    print("  ‚úì High-performance vector storage with FAISS")
    print("  ‚úì Multiple search modes (exact, approximate, hybrid)")
    print("  ‚úì Intelligent caching with LRU and TTL")
    print("  ‚úì Comprehensive metadata management")
    print("  ‚úì Performance monitoring and statistics")
    print("  ‚úì Index backup and recovery")
    print("  ‚úì Thread-safe concurrent operations")
    print("  ‚úì Memory-efficient vector normalization")
    print("  ‚úì Enterprise-grade error handling")

if __name__ == "__main__":
    asyncio.run(main()) 